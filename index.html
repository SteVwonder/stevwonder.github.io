<!doctype html><html><head><meta name=generator content="Hugo 0.150.0"><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=author content="Stephen Herbein"><meta name=description content="The personal site of Stephen Herbein, a software engineer."><link rel=stylesheet href=https://use.typekit.net/mym7qil.css><link rel=stylesheet href=/css/style.css><link rel=stylesheet href=/css/font-icons.css><link rel=stylesheet href=/css/academic.css><link rel=stylesheet href=/css/custom.css><meta name=viewport content="width=device-width,initial-scale=1"><title>Stephen Herbein</title></head><body class="stretched side-header"><button type=button class="btn body-scheme-toggle btn-dark" data-bodyclass-toggle=dark data-add-class=btn-warning data-remove-class=btn-dark data-add-html="<i class='bi-brightness-high align-middle'></i><span class='visually-hidden'>Light Mode</span>" data-remove-html="<i class='bi-moon-stars align-middle'></i><span class='visually-hidden'>Dark Mode</span>"><i class="bi-moon-stars align-middle"></i><span class=visually-hidden>Dark Mode</span></button><div id=wrapper><header id=header><div id=header-wrap class=border-0><div class=container><div class="header-row justify-content-lg-between px-4 px-xl-0"><div class="order-1 order-lg-1 text-lg-center py-lg-4 mt-lg-5"><img src=/img/profile.jpg alt="Stephen's Profile Photo" class="rounded-circle square square-lg mb-lg-3 d-none d-lg-inline-block"><div><h3 class="mb-0 fw-normal lh-1">Stephen Herbein</h3><p class="mb-0 op-06 fw-light">Software Engineer</p></div></div><div class="primary-menu-trigger order-3 order-lg-2"><button class=cnvs-hamburger type=button title="Open Mobile Menu">
<span class=cnvs-hamburger-box><span class=cnvs-hamburger-inner></span></span></button></div><div class="header-misc order-2 order-lg-last ms-auto"><div class="d-flex justify-content-center w-100 py-4"><a href=https://github.com/SteVwonder class="social-icon si-small rounded-circle bg-contrast-200 mx-lg-1 h-bg-github" style=--cnvs-socialicon-border:0;--cnvs-socialicon-lineheight:2rem><i class="fa-brands fa-github"></i>
<i class="fa-brands fa-github"></i>
</a><a href=https://twitter.com/stephenherbein class="social-icon si-small rounded-circle bg-contrast-200 mx-lg-1 h-bg-twitter" style=--cnvs-socialicon-border:0;--cnvs-socialicon-lineheight:2rem><i class="fa-brands fa-twitter"></i>
<i class="fa-brands fa-twitter"></i>
</a><a href=https://www.instagram.com/stephen272/ class="social-icon si-small rounded-circle bg-contrast-200 mx-lg-1 h-bg-instagram" style=--cnvs-socialicon-border:0;--cnvs-socialicon-lineheight:2rem><i class="fa-brands fa-instagram"></i>
<i class="fa-brands fa-instagram"></i>
</a><a href=https://www.linkedin.com/in/stephen-herbein/ class="social-icon si-small rounded-circle bg-contrast-200 mx-lg-1 h-bg-linkedin" style=--cnvs-socialicon-border:0;--cnvs-socialicon-lineheight:2rem><i class="fa-brands fa-linkedin"></i>
<i class="fa-brands fa-linkedin"></i></a></div></div><nav class="primary-menu order-last order-lg-2"><ul class="menu-container one-page-menu" data-easing=easeOutExpo data-speed=1250 data-offset=0><li class=menu-item><a class=menu-link href=/#section-about data-href=#section-about><div><i class=bi-person-circle></i> About</div></a></li><li class=menu-item><a class=menu-link href=/#section-education data-href=#section-education><div><i class=bi-book></i> Education</div></a></li><li class=menu-item><a class=menu-link href=/#section-experience data-href=#section-experience><div><i class=bi-briefcase></i> Experience</div></a></li><li class=menu-item><a class=menu-link href=/#section-awards data-href=#section-awards><div><i class=bi-award></i> Awards</div></a></li><li class=menu-item><a class=menu-link href=/#section-publications data-href=#section-publications><div><i class=bi-journal-text></i> Top Publications</div></a></li><a href=files/herbein-cv.pdf class="button button-rounded button-amber"><i class=bi-download></i>My CV</a></ul></nav></div></div></div><div class=header-wrap-clone></div></header><section id=content><div class="content-wrap py-lg-0 pt-0 px-4"><main aria-role=main><header class=homepage-header></header><div class=homepage-content><div id=section-about class="page-section py-5 pt-6"><div class="container mw-md pt-lg-3"><div class="row align-items-center justify-content-between"><div class=col-md-5><h2 class="display-2 fw-bolder text-uppercase ls-2">Stephen Herbein</h2><blockquote class="fs-6 border-color"><p class=mb-0>I am a software engineer specializing in distributed systems and job scheduling. I am passionate about learning and making the world a better place.</p></blockquote></div><div class=col-md-7><img src=/img/profile-big.jpg alt="Stephen's Profile Picture"></div></div></div></div><div class=line></div><div id=section-education class="page-section py-5"><div class="container mw-md pt-lg-3"><div class="row gx-5 justify-content-center"><div class=col-md-10><h2 class="text-center display-3 fw-semibold ls-2"><i class=color></i>
Education</h2><div class="row gy-5 justify-content-between"><div class="col-md-6 mt-5"><h3 class="border-bottom border-color border-width-3 d-inline-block"><i class=bi-mortarboard></i>
Degrees</h3><div class="feature-box-border-vertical col-mb-30 justify-content-center align-items-center"><div class="col-12 feature-box fbox-active fbox-light fbox-sm fbox-border"><div class=fbox-icon><i class="fa-solid fa-check"></i></div><div class=fbox-content><h3>Ph.D. in Computer Science</h3><p class="op-08 mt-0">University of Delaware, 2018</p><p class=mt-0>4.0 GPA</p></div></div><div class=clear></div><div class="col-12 feature-box fbox-active fbox-light fbox-sm fbox-border"><div class=fbox-icon><i class="fa-solid fa-check"></i></div><div class=fbox-content><h3>M.S. in Computer Science</h3><p class="op-08 mt-0">University of Delaware, 2016</p><p class=mt-0>4.0 GPA</p></div></div><div class=clear></div><div class="col-12 feature-box fbox-active fbox-light fbox-sm noborder"><div class=fbox-icon><i class="fa-solid fa-check"></i></div><div class=fbox-content><h3>B.S. in Computer Science</h3><p class="op-08 mt-0">University of Delaware, 2014</p><p class=mt-0>3.932 GPA</p></div></div></div></div><div class="col-md-6 mt-5"><h3 class="border-bottom border-color border-width-3 d-inline-block"><i class=bi-cloud></i>
Online Courses</h3><div class=clear></div><div class="feature-box fbox-plain fbox-sm"><div class=fbox-icon><i class="fa-solid fa-check"></i></div><div class=fbox-content><h3>Self-Driving Cars Specialization</h3><p class="op-08 mt-0">Coursera, 2022</p></div></div></div></div></div></div></div></div><div class=line></div><div id=section-experience class="page-section py-5"><div class="container mw-md"><div class="row gx-5 justify-content-center"><div class=col-md-12><h2 class="text-center display-3 fw-semibold ls-2 mb-5"><i class="bi-briefcase color"></i>
Experience</h2><div class="toggle mb-0" data-state=open><div class="toggle-header align-items-center"><div class=toggle-title><div class="toggle-title fs-4">Senior Software Engineer</div><div class="toggle-title fw-extralight">Nvidia</div></div><h3 class="mb-0 font-body me-3">2022 - Present</h3><div class="toggle-icon fs-4"><i class="toggle-closed bi-plus"></i>
<i class="toggle-open bi-dash color"></i></div></div><div class=toggle-content><a href=https://www.nvidia.com/en-us/on-demand/session/gtcfall20-a21846/>Maglev</a>: Creating MLOps infrastructure for autonomous vehicle development</div></div><div class="divider my-4"></div><div class="toggle mb-0"><div class="toggle-header align-items-center"><div class=toggle-title><div class="toggle-title fs-4">Computer Scientist</div><div class="toggle-title fw-extralight">Lawrence Livermore Nat'l Lab</div></div><h3 class="mb-0 font-body me-3">2018 - 2022</h3><div class="toggle-icon fs-4"><i class="toggle-closed bi-plus"></i>
<i class="toggle-open bi-dash color"></i></div></div><div class=toggle-content><ul><li><a href=https://github.com/flux-framework/>Flux</a>: developed features,
supported users, and readied code for future Exascale system - El
Capitan</li><li>HPC+Cloud: PI of $175K project to find gaps in LLNL’s converged
computing capabilities</li><li><a href=https://exaworks.org/>Exaworks</a>: created a portable, performant, and
hardened workflow SDK</li><li><a href=https://github.com/LLNL/zfp>ZFP</a>: developed python bindings for this
LLNL compression library</li></ul></div></div><div class="divider my-4"></div><div class="toggle mb-0"><div class="toggle-header align-items-center"><div class=toggle-title><div class="toggle-title fs-4">Research Assistant</div><div class="toggle-title fw-extralight">University of Delaware</div></div><h3 class="mb-0 font-body me-3">2012 - 2018</h3><div class="toggle-icon fs-4"><i class="toggle-closed bi-plus"></i>
<i class="toggle-open bi-dash color"></i></div></div><div class=toggle-content><ul><li>2014-2018: Created next-generation I/O-aware and hierarchical job
schedulers for HPC clusters utilizing the
<a href=https://github.com/flux-framework/>Flux</a> resource manager.</li><li>2014: Developed a suite of tools to profile, auto-tune, and optimize
applications developed with the parallel I/O library
<a href=https://www.olcf.ornl.gov/center-projects/adios/>ADIOS</a>.</li><li>2013: Integrated in-transit analysis and staging into the scientific
application <a href=https://sites.google.com/a/cmscc.org/qmcpack/>QMCPack</a> to
improve I/O performance and scalability.</li><li>2012: Developed a crowdsourcing web application,
<a href=http://www.exscitech.org/>ExSciTecH</a>, to complement the volunteer
computing project <a href=http://docking.cis.udel.edu/>Docking@Home</a>.</li></ul></div></div><div class="divider my-4"></div><div class="toggle mb-0"><div class="toggle-header align-items-center"><div class=toggle-title><div class="toggle-title fs-4">Research Intern</div><div class="toggle-title fw-extralight">Lawrence Livermore Nat'l Lab</div></div><h3 class="mb-0 font-body me-3">2014-2017</h3><div class="toggle-icon fs-4"><i class="toggle-closed bi-plus"></i>
<i class="toggle-open bi-dash color"></i></div></div><div class=toggle-content><ul><li>2017: Integrated my hierarchical scheduler with the Uncertainty
Quantification Pipeline (UQP), resulting in a 37% improvement in workload
runtime</li><li>2016: Added dynamicity to my hierarchical scheduler to eliminate
resource fragmentation</li><li>2015: Developed an automatic job aggregator and hierarchical scheduler,
resulting in a 4x speed up over the existing scheduler</li><li>2014: Developed a discrete-event simulator for the next-generation
resource manager, <a href=https://github.com/flux-framework/>Flux</a></li></ul></div></div><div class="divider my-4"></div><div class="toggle mb-0"><div class="toggle-header align-items-center"><div class=toggle-title><div class="toggle-title fs-4">Science Undergrad Lab Intern (SULI)</div><div class="toggle-title fw-extralight">Oak Ridge Nat'l Lab</div></div><h3 class="mb-0 font-body me-3">2013</h3><div class="toggle-icon fs-4"><i class="toggle-closed bi-plus"></i>
<i class="toggle-open bi-dash color"></i></div></div><div class=toggle-content><ul><li>Integrated <a href=https://www.olcf.ornl.gov/center-projects/adios/>ADIOS</a>,
ORNL&rsquo;s IO framework, into
<a href=https://sites.google.com/a/cmscc.org/qmcpack/>QMCPack</a>, a quantum
monte-carlo simulator.</li><li>Examined the performance of various IO methods and techniques on
peta-scale systems like <a href=http://www.olcf.ornl.gov/titan/>Titan</a>.</li></ul></div></div><div class="divider my-4"></div><div class="toggle mb-0"><div class="toggle-header align-items-center"><div class=toggle-title><div class="toggle-title fs-4">Research Experience for Undergraduates (REU) Intern</div><div class="toggle-title fw-extralight">University of Houston</div></div><h3 class="mb-0 font-body me-3">2012</h3><div class="toggle-icon fs-4"><i class="toggle-closed bi-plus"></i>
<i class="toggle-open bi-dash color"></i></div></div><div class=toggle-content><ul><li>Optimized <a href="http://dl.acm.org/citation.cfm?id=1612233">VolpexMPI</a> library
for use on large-scale clusters.</li></ul></div></div></div></div></div></div></div><div class=line></div><div id=section-awards class="page-section py-5"><div class="container mw-md"><div class=col-md-12><div class=row><h2 class="text-center display-3 fw-semibold ls-2 mb-0"><i class="bi-award color"></i>
Awards</h2><div class="col-md-6 mt-5"><h3 class="border-bottom border-color border-width-3 d-inline-block"><i class=bi-award></i>
Professional</h3><div class="row feature-box-border-vertical col-mb-30 justify-content-center align-items-center"><div class="col-12 feature-box fbox-active fbox-light fbox-sm fbox-border"><div class=fbox-icon><i class="fa-solid fa-check"></i></div><div class=fbox-content><h3>R&amp;D 100 Award - ZFP</h3><p class="op-08 mt-0">R&amp;D World, 2023</p></div></div><div class=clear></div><div class="col-12 feature-box fbox-active fbox-light fbox-sm fbox-border"><div class=fbox-icon><i class="fa-solid fa-check"></i></div><div class=fbox-content><h3>Best Paper Award</h3><p class="op-08 mt-0">International Conference on e-Science, 2022</p></div></div><div class=clear></div><div class="col-12 feature-box fbox-active fbox-light fbox-sm fbox-border"><div class=fbox-icon><i class="fa-solid fa-check"></i></div><div class=fbox-content><h3>R&amp;D 100 Award - Flux</h3><p class="op-08 mt-0">R&amp;D World, 2021</p></div></div><div class=clear></div><div class="col-12 feature-box fbox-active fbox-light fbox-sm fbox-border"><div class=fbox-icon><i class="fa-solid fa-check"></i></div><div class=fbox-content><h3>Spot Award</h3><p class="op-08 mt-0">LLNL ATDM Next Generation Computing Enablement, 2019</p></div></div><div class=clear></div><div class="col-12 feature-box fbox-active fbox-light fbox-sm fbox-border"><div class=fbox-icon><i class="fa-solid fa-check"></i></div><div class=fbox-content><h3>Dissertation Award</h3><p class="op-08 mt-0">IEEE Technical Committee on Scalable Computing, 2019</p></div></div><div class=clear></div><div class="col-12 feature-box fbox-active fbox-light fbox-sm fbox-border"><div class=fbox-icon><i class="fa-solid fa-check"></i></div><div class=fbox-content><h3>Best Poster</h3><p class="op-08 mt-0">Annual LLNL Poster Symposium, 2016</p></div></div><div class=clear></div><div class="col-12 feature-box fbox-active fbox-light fbox-sm noborder"><div class=fbox-icon><i class="fa-solid fa-check"></i></div><div class=fbox-content><h3>Undergraduate Student Research Competition Award</h3><p class="op-08 mt-0">ACM, 2013</p></div></div></div></div><div class="col-md-6 mt-5"><h3 class="border-bottom border-color border-width-3 d-inline-block"><i class=bi-award></i>
Academic</h3><div class="row feature-box-border-vertical col-mb-30 justify-content-center align-items-center"><div class="col-12 feature-box fbox-active fbox-light fbox-sm fbox-border"><div class=fbox-icon><i class="fa-solid fa-check"></i></div><div class=fbox-content><h3>Outstanding Graduate Student Award</h3><p class="op-08 mt-0">CIS Department, 2016</p></div></div><div class=clear></div><div class="col-12 feature-box fbox-active fbox-light fbox-sm fbox-border"><div class=fbox-icon><i class="fa-solid fa-check"></i></div><div class=fbox-content><h3>Outstanding Senior Student Award</h3><p class="op-08 mt-0">CIS Department, 2014</p></div></div><div class=clear></div><div class="col-12 feature-box fbox-active fbox-light fbox-sm fbox-border"><div class=fbox-icon><i class="fa-solid fa-check"></i></div><div class=fbox-content><h3>Outstanding Junior Student Award</h3><p class="op-08 mt-0">CIS Department, 2013</p></div></div><div class=clear></div><div class="col-12 feature-box fbox-active fbox-light fbox-sm fbox-border"><div class=fbox-icon><i class="fa-solid fa-check"></i></div><div class=fbox-content><h3>General Honors Award</h3><p class="op-08 mt-0">University of Delaware, Fall 2012</p></div></div><div class=clear></div><div class="col-12 feature-box fbox-active fbox-light fbox-sm noborder"><div class=fbox-icon><i class="fa-solid fa-check"></i></div><div class=fbox-content><h3>Presidential Achievement Scholarship</h3><p class="op-08 mt-0">University of Delaware, 2011 - 2014</p></div></div></div></div></div></div></div></div><div class=line></div><div id=section-publications class="page-section py-5"><div class="container mw-md"><h2 class="text-center display-3 fw-semibold ls-2 mb-5"><i class="bi-journal-text color"></i> Top Publications</h2><div class="row gy-4"><div class=col-12><div class="card bg-contrast-100 rounded-1 border-0"><div class="card-body p-4"><div class="toggle mb-0"><div class="toggle-header d-block"><div class="d-flex w-100"><div class="toggle-title fs-4 mb-2">Scalable Composition and Analysis Techniques for Massive Scientific Workflows</div></div><div class="small fw-normal mb-2 op-06">D. Ahn, X. Zhang, J. Mast, <strong class=color>S. Herbein</strong>, F. Di Natale, D. Kirshner, S. Ade Jacobs, I. Karlin, D. Milroy, B. De Supinski, B. Van Essen, J. Allen, and F. C. Lightstone</div><div class="badge bg-warning fs-6 fw-normal mt-2 me-2">Best Paper</div><small class=fw-normal><i>18th IEEE International Conference on e-Science (e-Science)</i>, Oct 2022</small><div class="position-absolute bottom-0 end-0 d-flex align-items-center"><a href=https://ieeexplore.ieee.org/document/9973491 class="bi-link fs-5 text-contrast-900 h-text-color ms-3" style=transform:rotate(45deg)></a></div></div><div class=toggle-content><div class="mt-4 border-top pt-4"><h4 class=mb-3>Abstract</h4>Composite science workflows are gaining traction to manage the combined effects of (1) extreme hardware heterogeneity in new High Performance Computing (HPC) systems and (2) growing software complexity – effects necessitated by the convergence of traditional HPC with data sciences. Composing, analyzing, and optimizing a composite workflow remains highly challenging as the component technologies are generally developed in isolation and often feature widely varying levels of performance, scalability, and interoperability. In this paper, we propose novel workflow composition and analysis techniques to create and optimize a scalable and effective composite workflow for heterogeneous HPC centers, and define the performance space of variables that impact composite workflow performance. We present PerfFlowAspect, an Aspect Oriented Programming (AOP)-based tool to perform cross-cutting performance analysis of composite workflows and better understand the impact of key performance variables on workflows. Our solution directly addresses AOP concerns that can affect workflow performance and covers the full software lifecycle, ranging from the workflow&rsquo;s initial composition through performance analysis and optimization. We use our science workflow composition techniques to implement the American Heart Association Molecule Screening (AHA MoleS) workflow. Through experimentation, we demonstrate that tuning a single performance variable can improve AHA MoleS workflow performance by a factor of up to 2.45x. Our evaluation suggests that our techniques can significantly enhance the ability of a multi-disciplinary research and development team to create a high performance composite workflow.</div></div></div></div></div></div><div class=col-12><div class="card bg-contrast-100 rounded-1 border-0"><div class="card-body p-4"><div class="toggle mb-0"><div class="toggle-header d-block"><div class="d-flex w-100"><div class="toggle-title fs-4 mb-2">Flux: Overcoming Scheduling Challenges for Exascale Workflows</div></div><div class="small fw-normal mb-2 op-06">D.H. Ahn, N. Bass, A. Chu, J. Garlick, M. Grondona, <strong class=color>S. Herbein</strong>, J. Koning, T. Patki, T.R.W. Scogland, B. Springmeyer, and M. Taufer</div><small class=fw-normal><i>13th Workshop on Workflows in Support of Large-Scale Science (WORKS)</i>, November 2018</small><div class="position-absolute bottom-0 end-0 d-flex align-items-center"><a href=https://dx.doi.org/10.1109/WORKS.2018.00007 class="bi-link fs-5 text-contrast-900 h-text-color ms-3" style=transform:rotate(45deg)></a></div></div><div class=toggle-content><div class="mt-4 border-top pt-4"><h4 class=mb-3>Abstract</h4>Many emerging scientific workflows that target high-end HPC systems require complex interplay with the resource and job management software~(RJMS). However, portable, efficient and easy-to-use scheduling and execution of these workflows is still an unsolved problem. We present Flux, a novel, hierarchical RJMS infrastructure that addresses the key scheduling challenges of modern workflows in a scalable, easy-to-use, and portable manner. At the heart of Flux lies its ability to be nested seamlessly within batch allocations created by other schedulers as well as itself. Once a hierarchy of Flux instance is created within each allocation, its consistent and rich set of well-defined APIs portably and efficiently support those workflows that can often feature non-traditional execution patterns such as requirements for complex co-scheduling, massive ensembles of small jobs and coordination among jobs in an ensemble.</div></div></div></div></div></div><div class=col-12><div class="card bg-contrast-100 rounded-1 border-0"><div class="card-body p-4"><div class="toggle mb-0"><div class="toggle-header d-block"><div class="d-flex w-100"><div class="toggle-title fs-4 mb-2">Scalable I/O-Aware Job Scheduling for Burst Buffer Enabled HPC Clusters</div></div><div class="small fw-normal mb-2 op-06"><strong class=color>S. Herbein</strong>, D. H. Ahn, D. Lipari, T. R.W. Scogland, M. Stearman, M. Grondona, J. Garlick, B. Springmeyer, and M. Taufer</div><small class=fw-normal><i>25th International Symposium on High-Performance Parallel and Distributed Computing (HPDC)</i>, June 2016</small><div class="position-absolute bottom-0 end-0 d-flex align-items-center"><a href=https://dl.acm.org/doi/10.1145/2907294.2907316 class="bi-link fs-5 text-contrast-900 h-text-color ms-3" style=transform:rotate(45deg)></a></div></div><div class=toggle-content><div class="mt-4 border-top pt-4"><h4 class=mb-3>Abstract</h4>The economics of flash vs. disk storage is driving HPC centers to incorporate faster solid-state burst buffers into the storage hierarchy in exchange for smaller parallel file system (PFS) bandwidth. In systems with an underprovisioned PFS, avoiding I/O contention at the PFS level will become crucial to achieving high computational efficiency. In this paper, we propose novel batch job scheduling techniques that reduce such contention by integrating I/O awareness into scheduling policies such as EASY backfilling. We model the available bandwidth of links between each level of the storage hierarchy (i.e., burst buffers, I/O network, and PFS), and our I/O-aware schedulers use this model to avoid contention at any level in the hierarchy. We integrate our approach into Flux, a next-generation resource and job management framework, and evaluate the effectiveness and computational costs of our I/O-aware scheduling. Our results show that by reducing I/O contention for underprovisioned PFSes, our solution reduces job performance variability by up to 33% and decreases I/O-related utilization losses by up to 21%, which ultimately increases the amount of science performed by scientific workloads.</div></div></div></div></div></div><div class=col-12><div class="card bg-contrast-100 rounded-1 border-0"><div class="card-body p-4"><div class="toggle mb-0"><div class="toggle-header d-block"><div class="d-flex w-100"><div class="toggle-title fs-4 mb-2">PRIONN: Predicting Runtime and IO using Neural Networks</div></div><div class="small fw-normal mb-2 op-06">M. Wyatt, <strong class=color>S. Herbein</strong>, T. Gamblin, A. Moody, D.H. Ahn, and M. Taufer</div><small class=fw-normal><i>47th International Conference on Parallel Processing (ICPP)</i>, August 2018</small><div class="position-absolute bottom-0 end-0 d-flex align-items-center"><a href=https://dx.doi.org/10.1145/3225058.3225091 class="bi-link fs-5 text-contrast-900 h-text-color ms-3" style=transform:rotate(45deg)></a></div></div><div class=toggle-content><div class="mt-4 border-top pt-4"><h4 class=mb-3>Abstract</h4><p>For job allocation decision, current batch schedulers have access to and use only information on the number of nodes and runtime because it is readily available at submission time from user job scripts. User-provided runtimes are typically inaccurate because users overestimate or lack understanding of job resource requirements. Beyond the number of nodes and runtime, other system resources, including IO and network, are not available but play a key role in system performance. There is the need for automatic, general, and scalable tools that provide accurate resource usage information to schedulers so that, by becoming resource-aware, they can better manage system resources.</p><p>We tackle this need by presenting a tool for Predicting Runtime and IO using Neural Networks (PRIONN). PRIONN automates prediction of per-job runtime and IO resource usage, enabling IO-aware scheduling on HPC systems. The novelty of our tool is the input of whole job scripts into deep learning models that allows complete automation of runtime and IO resource predictions. We demonstrate the power of PRIONN with runtime and IO resource predictions applied to IO-aware scheduling for real HPC data. Specifically, we achieve over 75% mean and 98% median accuracy for runtime and IO predictions across 300,000 jobs from a real HPC machine. We combine our per-job runtime and IO predictions with queue and system simulations to predict future system IO usage accurately. We predict over 50% of IO bursts in advance on a real HPC system.</p></div></div></div></div></div></div><div class=col-12><div class="card bg-contrast-100 rounded-1 border-0"><div class="card-body p-4"><div class="toggle mb-0"><div class="toggle-header d-block"><div class="d-flex w-100"><div class="toggle-title fs-4 mb-2">Advanced Schedulers For Next-Generation HPC Systems</div></div><div class="small fw-normal mb-2 op-06"><strong class=color>S. Herbein</strong></div><div class="badge bg-warning fs-6 fw-normal mt-2 me-2">Thesis</div><small class=fw-normal><i>University of Delaware</i>, 2018</small><div class="position-absolute bottom-0 end-0 d-flex align-items-center"><a href=/files/herbein-thesis.pdf class="bi-link fs-5 text-contrast-900 h-text-color ms-3" style=transform:rotate(45deg)></a></div></div><div class=toggle-content><div class="mt-4 border-top pt-4"><h4 class=mb-3>Abstract</h4>High performance computing (HPC) is undergoing many changes at both the system and workload levels. At the system level, data movement is becoming more costly in relation to computation and HPC centers are becoming increasingly power-constrained. In an effort to adapt to these trends, HPC systems are including new resources such as burst buffers and GPUs which makes the resource set larger and more diverse. At the workload level, new ensemble workloads,such as uncertainty quantification (UQ), are emerging within HPC, driving up the workload scale in terms of the number of jobs. Existing HPC scheduling models are unable to adapt to these changes, leading to degraded system efficiency and application performance. In this thesis, we claim that new schedulers are needed to overcome the challenges mentioned above and efficiently manage the next-generation of HPC systems. To this end we design, implement, and evaluate three fundamental transformations to the existing scheduling models. First, we integrate I/O-awareness into existing scheduling policies and demonstrate that I/O-aware scheduling increase the efficiency of burst buffer-enabled HPC systems. Second,we expand our I/O-aware scheduler to incorporate the accurate knowledge of application I/O utilization patterns provided by machine learning models. Third, we design a prototype scheduler based on the fully hierarchical scheduling model and show that it reduces scheduler overhead and increases job throughput on synthetic and real-world ensemble workloads, such as UQ. Our work is the first step towards a new generation of scheduling models for HPC.</div></div></div></div></div></div></div></div></div></div></main></div></section><footer id=footer class="bg-contrast-0 border-width-1"><div id=copyrights class=bg-color><div class=container><p class="mb-0 text-center text-dark text-opacity-75">Copyrights &copy; 2023 All Rights Reserved by Stephen Herbein.</p></div></div></footer></div><div id=gotoTop class="uil uil-angle-up"></div><script src=/js/functions.js></script></body></html>